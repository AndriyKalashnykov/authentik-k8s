#---
## Source: cockroachdb/templates/poddisruptionbudget.yaml
#kind: PodDisruptionBudget
#apiVersion: policy/v1
#metadata:
#  name: crdb-budget
#  namespace: "threeport-api"
#  labels:
#    helm.sh/chart: cockroachdb-10.0.2
#    app.kubernetes.io/name: cockroachdb
#    app.kubernetes.io/instance: "crdb"
#    app.kubernetes.io/managed-by: "Helm"
#spec:
#  selector:
#    matchLabels:
#      app.kubernetes.io/name: cockroachdb
#      app.kubernetes.io/instance: "crdb"
#      app.kubernetes.io/component: cockroachdb
#  maxUnavailable: 1
#---
## Source: cockroachdb/templates/secrets.init.yaml
#apiVersion: v1
#kind: Secret
#metadata:
#  name: crdb-init
#  namespace: "threeport-api"
#type: Opaque
#stringData:
#  tp_rest_api-password: "tp-rest-api-pwd"
---
# Source: cockroachdb/templates/service.discovery.yaml
# This service only exists to create DNS entries for each pod in
# the StatefulSet such that they can resolve each other's IP addresses.
# It does not create a load-balanced ClusterIP and should not be used directly
# by clients in most circumstances.
kind: Service
apiVersion: v1
metadata:
  name: crdb
  namespace: "threeport-api"
  labels:
    helm.sh/chart: cockroachdb-10.0.2
    app.kubernetes.io/name: cockroachdb
    app.kubernetes.io/instance: "crdb"
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/component: cockroachdb
  annotations:
    # Use this annotation in addition to the actual field below because the
    # annotation will stop being respected soon, but the field is broken in
    # some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
    # Enable automatic monitoring of all instances when Prometheus is running
    # in the cluster.
    prometheus.io/scrape: "true"
    prometheus.io/path: _status/vars
    prometheus.io/port: "8080"
spec:
  clusterIP: None
  # We want all Pods in the StatefulSet to have their addresses published for
  # the sake of the other CockroachDB Pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    # The main port, served by gRPC, serves Postgres-flavor SQL, inter-node
    # traffic and the CLI.
    - name: "grpc"
      port: 26257
      targetPort: grpc
    # The secondary port serves the UI as well as health and debug endpoints.
    - name: "http"
      port: 8080
      targetPort: http
  selector:
    app.kubernetes.io/name: cockroachdb
    app.kubernetes.io/instance: "crdb"
    app.kubernetes.io/component: cockroachdb
---
# Source: cockroachdb/templates/service.public.yaml
# This Service is meant to be used by clients of the database.
# It exposes a ClusterIP that will automatically load balance connections
# to the different database Pods.
kind: Service
apiVersion: v1
metadata:
  name: crdb-public
  namespace: "threeport-api"
  labels:
    helm.sh/chart: cockroachdb-10.0.2
    app.kubernetes.io/name: cockroachdb
    app.kubernetes.io/instance: "crdb"
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/component: cockroachdb
spec:
  type: LoadBalancer
  ports:
    # The main port, served by gRPC, serves Postgres-flavor SQL, inter-node
    # traffic and the CLI.
    - name: "grpc"
      port: 26257
      targetPort: grpc
    # The secondary port serves the UI as well as health and debug endpoints.
    - name: "http"
      port: 8080
      targetPort: http
  selector:
    app.kubernetes.io/name: cockroachdb
    app.kubernetes.io/instance: "crdb"
    app.kubernetes.io/component: cockroachdb
---
# Source: cockroachdb/templates/statefulset.yaml
kind: StatefulSet
apiVersion: apps/v1
metadata:
  name: crdb
  namespace: "threeport-api"
  labels:
    helm.sh/chart: cockroachdb-10.0.2
    app.kubernetes.io/name: cockroachdb
    app.kubernetes.io/instance: "crdb"
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/component: cockroachdb
spec:
  serviceName: crdb
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  podManagementPolicy: "Parallel"
  selector:
    matchLabels:
      app.kubernetes.io/name: cockroachdb
      app.kubernetes.io/instance: "crdb"
      app.kubernetes.io/component: cockroachdb
  template:
    metadata:
      labels:
        app.kubernetes.io/name: cockroachdb
        app.kubernetes.io/instance: "crdb"
        app.kubernetes.io/component: cockroachdb
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                topologyKey: kubernetes.io/hostname
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: cockroachdb
                    app.kubernetes.io/instance: "crdb"
                    app.kubernetes.io/component: cockroachdb
      topologySpreadConstraints:
        - labelSelector:
            matchLabels:
              app.kubernetes.io/name: cockroachdb
              app.kubernetes.io/instance: "crdb"
              app.kubernetes.io/component: cockroachdb
          maxSkew: 1
          topologyKey: topology.kubernetes.io/zone
          whenUnsatisfiable: ScheduleAnyway
      # No pre-stop hook is required, a SIGTERM plus some time is all that's
      # needed for graceful shutdown of a node.
      terminationGracePeriodSeconds: 60
      containers:
        - name: db
          image: "cockroachdb/cockroach:v22.2.2"
          imagePullPolicy: "IfNotPresent"
          args:
            - shell
            - -ecx
            # The use of qualified `hostname -f` is crucial:
            # Other nodes aren't able to look up the unqualified hostname.
            #
            # `--join` CLI flag is hardcoded to exactly 3 Pods, because:
            # 1. Having `--join` value depending on `statefulset.replicas`
            #    will trigger undesired restart of existing Pods when
            #    StatefulSet is scaled up/down. We want to scale without
            #    restarting existing Pods.
            # 2. At least one Pod in `--join` is enough to successfully
            #    join CockroachDB cluster and gossip with all other existing
            #    Pods, even if there are 3 or more Pods.
            # 3. It's harmless for `--join` to have 3 Pods even for 1-Pod
            #    clusters, while it gives us opportunity to scale up even if
            #    some Pods of existing cluster are down (for whatever reason).
            # See details explained here:
            # https://github.com/helm/charts/pull/18993#issuecomment-558795102
            - >-
              exec /cockroach/cockroach
              start-single-node
              --advertise-host=$(hostname).${STATEFULSET_FQDN}
              --insecure
              --http-port=8080
              --port=26257
              --cache=25%
              --max-sql-memory=25%
              --logtostderr=INFO
          env:
            - name: STATEFULSET_NAME
              value: crdb
            - name: STATEFULSET_FQDN
              value: crdb.threeport-api.svc.cluster.local
            - name: COCKROACH_CHANNEL
              value: kubernetes-helm
          ports:
            - name: grpc
              containerPort: 26257
              protocol: TCP
            - name: http
              containerPort: 8080
              protocol: TCP
          volumeMounts:
            - name: datadir
              mountPath: /cockroach/cockroach-data/
          livenessProbe:
            httpGet:
              path: /health
              port: http
            initialDelaySeconds: 30
            periodSeconds: 5
          readinessProbe:
            httpGet:
              path: /health?ready=1
              port: http
            initialDelaySeconds: 10
            periodSeconds: 5
            failureThreshold: 2
      volumes:
        - name: datadir
          persistentVolumeClaim:
            claimName: datadir
  volumeClaimTemplates:
    - metadata:
        name: datadir
        labels:
          app.kubernetes.io/name: cockroachdb
          app.kubernetes.io/instance: "crdb"
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: "1Gi"
#---
## Source: cockroachdb/templates/cronjob-client-node-certSelfSigner.yaml
#apiVersion: batch/v1
#kind: CronJob
#metadata:
#  name: crdb-rotate-self-signer-client
#  namespace: "threeport-api"
#  labels:
#    helm.sh/chart: cockroachdb-10.0.2
#    app.kubernetes.io/name: cockroachdb
#    app.kubernetes.io/instance: "crdb"
#    app.kubernetes.io/managed-by: "Helm"
#spec:
#  schedule: 0 0 */26 * *
#  jobTemplate:
#    spec:
#      backoffLimit: 1
#      template:
#        spec:
#          restartPolicy: Never
#          containers:
#          - name: cert-rotate-job
#            image: "gcr.io/cockroachlabs-helm-charts/cockroach-self-signer-cert:1.3"
#            imagePullPolicy: "IfNotPresent"
#            args:
#            - rotate
#            - --ca-duration=43800h
#            - --ca-expiry=648h
#            - --client
#            - --client-duration=672h
#            - --client-expiry=48h
#            - --node
#            - --node-duration=8760h
#            - --node-expiry=168h
#            - --node-client-cron=0 0 */26 * *
#            - --readiness-wait=30s
#            - --pod-update-timeout=2m
#            env:
#            - name: STATEFULSET_NAME
#              value: crdb
#            - name: NAMESPACE
#              value: threeport-api
#            - name: CLUSTER_DOMAIN
#              value: cluster.local
#          serviceAccountName: crdb-rotate-self-signer
#---
## Source: cockroachdb/templates/tests/client.yaml
#kind: Pod
#apiVersion: v1
#metadata:
#  name: crdb-test
#  namespace: "threeport-api"
#  annotations:
#    helm.sh/hook: test-success
#spec:
#  restartPolicy: Never
#  containers:
#    - name: client-test
#      image: "cockroachdb/cockroach:v22.2.2"
#      imagePullPolicy: "IfNotPresent"
#      command:
#        - /cockroach/cockroach
#        - sql
#        - --insecure
#        - --host
#        - crdb-public.threeport-api
#        - --port
#        - "26257"
#        - -e
#        - SHOW DATABASES;
#---
## Source: cockroachdb/templates/job.init.yaml
#kind: Job
#apiVersion: batch/v1
#metadata:
#  name: crdb-init
#  namespace: "threeport-api"
#  labels:
#    helm.sh/chart: cockroachdb-10.0.2
#    app.kubernetes.io/name: cockroachdb
#    app.kubernetes.io/instance: "crdb"
#    app.kubernetes.io/managed-by: "Helm"
#    app.kubernetes.io/component: init
#  annotations:
#    helm.sh/hook: post-install,post-upgrade
#    helm.sh/hook-delete-policy: before-hook-creation
#spec:
#  template:
#    metadata:
#      labels:
#        app.kubernetes.io/name: cockroachdb
#        app.kubernetes.io/instance: "crdb"
#        app.kubernetes.io/component: init
#    spec:
#      restartPolicy: OnFailure
#      terminationGracePeriodSeconds: 0
#      containers:
#        - name: cluster-init
#          image: "cockroachdb/cockroach:v22.2.2"
#          imagePullPolicy: "IfNotPresent"
#          # Run the command in an `while true` loop because this Job is bound
#          # to come up before the CockroachDB Pods (due to the time needed to
#          # get PersistentVolumes attached to Nodes), and sleeping 5 seconds
#          # between attempts is much better than letting the Pod fail when
#          # the init command does and waiting out Kubernetes' non-configurable
#          # exponential back-off for Pod restarts.
#          # Command completes either when cluster initialization succeeds,
#          # or when cluster has been initialized already.
#          command:
#          - /bin/bash
#          - -c
#          - >-
#              provisionCluster() {
#                while true; do
#                  /cockroach/cockroach sql \
#                    --insecure \
#                    --host=crdb-0.crdb:26257 \
#                    --execute="
#                        CREATE USER IF NOT EXISTS tp_rest_api
#                          LOGIN
#                        ;
#                        CREATE DATABASE IF NOT EXISTS threeport_api
#                            encoding='utf-8'
#                        ;
#                        GRANT ALL ON DATABASE threeport_api TO tp_rest_api;
#                    "
#                  &>/dev/null;
#
#                  local exitCode="$?";
#
#                  if [[ "$exitCode" == "0" ]]
#                    then break;
#                  fi
#
#                  sleep 5;
#                done
#
#                echo "Provisioning completed successfully";
#              }
#
#              provisionCluster;
#          #env:
#          #- name: tp_rest_api_PASSWORD
#          #  valueFrom:
#          #    secretKeyRef:
#          #      name: crdb-init
#          #      key: tp_rest_api-password
